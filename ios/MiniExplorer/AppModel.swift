import Foundation
import AVFoundation
import Combine

/// Phase 5: Shared app-level state & services.
///
/// Goals:
/// - Keep a single instance of realtime/audio/camera services.
/// - Provide a single place to coordinate mode switching (Explore vs Companion).
@MainActor
final class AppModel: ObservableObject {
    enum Mode: String, CaseIterable {
        case explore
        case companion
    }

    enum ConversationState: String {
        case idle
        case listening
        case thinking
        case speaking
        case error
    }

    @Published var mode: Mode = .explore
    @Published var conversation: ConversationState = .idle

    /// Prevent rapid toggle / inconsistent UI state when starting/stopping audio.
    @Published var isMicBusy: Bool = false
    @Published var messages: [ChatMessage] = [
        ChatMessage(role: .system, text: "æ¬¢è¿æ¥åˆ°æ¢ç´¢æ¨¡å¼ã€‚æŒ‰ä½è¯´è¯ï¼Œæˆ–æ‹ç…§æé—®ã€‚")
    ]

    // Shared services (do not recreate on tab switches)
    let realtime = CozeRealtimeService()
    let audio = AudioService()
    let camera = CameraService()

    private var connectedBotId: String? = nil

    private var didBoot = false
    private var cancellables = Set<AnyCancellable>()

#if DEBUG
    private var didAutoSmoke = false
#endif

    /// Boot only the non-invasive parts (no camera, no network).
    func bootBasicsIfNeeded() {
        guard !didBoot else { return }
        didBoot = true

#if DEBUG
        // NOTE: Disabled by default for UI-only review videos (no recording).
        // autoSmokeIfNeeded()
#endif

        // Observe realtime events and drive a minimal state machine.
        realtime.$lastEventType
            .sink { [weak self] type in
                guard let self else { return }
                switch type {
                case "completed":
                    self.conversation = .speaking
                    let reply = self.realtime.lastCompletedText ?? "ï¼ˆæ”¶åˆ°å›å¤ï¼šstubï¼‰"
                    self.messages.append(ChatMessage(role: .assistant, text: reply))
                    // Auto settle back to idle.
                    Task { @MainActor in
                        try? await Task.sleep(nanoseconds: 900_000_000)
                        if self.conversation == .speaking { self.conversation = .idle }
                    }
                default:
                    break
                }
            }
            .store(in: &cancellables)

// DEBUG auto-connect removed; connectIfNeeded() handles this.
    }

    /// Enter a mode (invokes camera setup + realtime connect).
    func enterMode(_ newMode: Mode) {
        mode = newMode

        // Reset conversation UI state when switching modes.
        conversation = .idle

        switch newMode {
        case .explore:
            camera.setup(position: .back)
        case .companion:
            camera.setup(position: .front)
        }

        connectIfNeeded()
    }

    private func connectIfNeeded() {
        let botId: String
        switch mode {
        case .explore: botId = AppConfig.explorerBotID
        case .companion: botId = AppConfig.companionBotID
        }

        // Avoid spamming connect calls.
        guard connectedBotId != botId else { return }
        connectedBotId = botId
        NSLog("[ModeSwitch] switching botId -> %@", botId)

        Task {
            do {
                try await realtime.connect(botId: botId)
                messages.append(ChatMessage(role: .system, text: "å·²è¿æ¥ bot: \(botId)"))
            } catch {
                conversation = .error
                messages.append(ChatMessage(role: .system, text: "è¿æ¥å¤±è´¥ï¼š\(String(describing: error))"))
            }
        }
    }

    /// User intent: toggle mic (start/stop). Handles permission + race prevention.
    func toggleTalking() {
        Task { @MainActor in
            guard !isMicBusy else { return }
            isMicBusy = true
            defer { isMicBusy = false }

            if audio.isRecording {
                stopTalking()
                return
            }

            // Permission gate (device-only).
            let ok = await audio.ensureRecordPermission()
            guard ok else {
                conversation = .error
                messages.append(ChatMessage(role: .system, text: "éº¦å…‹é£æƒé™æœªå¼€å¯ï¼Œè¯·åœ¨è®¾ç½®ä¸­å…è®¸ MiniExplorer ä½¿ç”¨éº¦å…‹é£"))
                return
            }

            startTalking()

            // If startRecording failed (e.g. session category/engine start error), settle to error.
            if !audio.isRecording {
                conversation = .error
                let reason = audio.lastError ?? "unknown"
                messages.append(ChatMessage(role: .system, text: "å¼€å§‹å½•éŸ³å¤±è´¥ï¼š\(reason)"))
            }
        }
    }

    func startTalking() {
        guard !audio.isRecording else { return }

        conversation = .listening
        messages.append(ChatMessage(role: .user, text: "ğŸ™ï¸ï¼ˆå¼€å§‹è¯´è¯â€¦ï¼‰"))

        audio.startRecording { [weak self] data in
            guard let self else { return }
            self.realtime.sendAudio(data)
        }
    }

    func stopTalking() {
        guard audio.isRecording else {
            // If UI thought we're recording but audio didn't start, just normalize state.
            if conversation == .listening { conversation = .idle }
            return
        }
        audio.stopRecording()
        conversation = .thinking
        realtime.completeInput()
        messages.append(ChatMessage(role: .user, text: "âœ…ï¼ˆç»“æŸï¼‰"))
    }

    func captureAndSendPhoto() async {
        let img = await camera.capturePhoto()
        guard let img else {
            messages.append(ChatMessage(role: .system, text: "æ‹ç…§å¤±è´¥"))
            return
        }
        let url = await camera.uploadPhoto(img)
        guard let url else {
            messages.append(ChatMessage(role: .system, text: "ä¸Šä¼ å¤±è´¥"))
            return
        }
        messages.append(ChatMessage(role: .user, text: "ğŸ“· å·²ä¸Šä¼ å›¾ç‰‡ï¼š\(url.lastPathComponent)"))
        realtime.sendImage(url)
    }

#if DEBUG
    func autoSmokeIfNeeded() {
        guard !didAutoSmoke else { return }
        didAutoSmoke = true

        // Runtime evidence generator (main flow demo):
        // 1) Home (Explore) -> record -> stop -> assistant bubble
        // 2) Switch to Companion -> record -> stop -> assistant bubble
        Task { @MainActor in
            // Ensure we start at Explore.
            self.enterMode(.explore)
            self.messages.append(ChatMessage(role: .system, text: "(auto-smoke) Explore flow"))

            try? await Task.sleep(nanoseconds: 800_000_000)
            self.startTalking()
            try? await Task.sleep(nanoseconds: 900_000_000)
            self.stopTalking()

            // Wait a bit for completed event + UI settle.
            try? await Task.sleep(nanoseconds: 1_400_000_000)

            // Switch to Companion.
            self.enterMode(.companion)
            self.messages.append(ChatMessage(role: .system, text: "(auto-smoke) Companion flow"))

            try? await Task.sleep(nanoseconds: 800_000_000)
            self.startTalking()
            try? await Task.sleep(nanoseconds: 900_000_000)
            self.stopTalking()
        }
    }
#endif
}
